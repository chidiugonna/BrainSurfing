<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>practicum 9.1 - BrainSurfing</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "practicum 9.1";
    var mkdocs_page_input_path = "surfanalysis/prac91.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> BrainSurfing</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../about/">About</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Surface Formats</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../surfdata/prac81/">practicum 8.1</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Surface Analysis</span></p>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">practicum 9.1</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#synopsis">Synopsis</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#objectives">Objectives</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#downloadsinstallation">Downloads/Installation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#provenance">Provenance</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#scripts">Scripts</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#data">Data</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#initial-processing">Initial processing</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#task-1-create-midthickness-inflated-and-very-inflated-surfaces">Task 1: Create midthickness, inflated and very-inflated surfaces</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#task-2-use-multimodal-surface-matching-msm-to-register-a-native-mesh-to-the-164k-fs_lr-template">Task 2: Use MultiModal Surface Matching (MSM) to register a native mesh to the 164k fs_LR template</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#task-3-project-volumetric-data-onto-a-gifti-surface">Task 3: Project volumetric data onto a GIFTI Surface</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#task-4-convert-volumetric-functional-data-into-a-cifti-file">Task 4: Convert volumetric functional data into a CIFTI file</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#task-5-spatial-smoothing">Task 5: Spatial Smoothing</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#extra-time">Extra Time?</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#final-words">Final words</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#acknowledgements">Acknowledgements</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#references">References</a>
    </li>
    </ul>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">BrainSurfing</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Surface Analysis &raquo;</li>
        
      
    
    <li>practicum 9.1</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="practicum-91-surface-based-analysis">Practicum 9.1 -  Surface-Based Analysis</h1>
<h2 id="synopsis">Synopsis</h2>
<p>Surface-based methods provide several advantages over volume-based methods for analysing data on the cerebral cortex [Dickie et al. 2019, Coalson et al. 2018, Glasser et al. 2013]. Fundamentally, they seem to provide a more neurobiologically valid representation of the way that function is mapped along the surface of the cortex as a 2D metric [Glasser et al. 2013] . This in turn affords other downstream benefits that make surface-based approaches attractive for studying the cortex.</p>
<p>These benefits include the facilitation of more computationally tractable algorithms for aligning cortical convolutions across many subjects thus leading to better alignment of functional areas [Coalsson et al. 2018] and the encouragement of constrained spatial smoothing methods that reduce the corruption of functional signal from non-related parts of the brain [Dickie et al. 2019]. These two benefits improve the statistical power of surface based studies. Surface-based methods also allow for much better visualization of cortical patterns of structure and function by the use of inflated and flat surfaces that expose sulci that are usually hidden in the volume. </p>
<p>In addition, surface-based models of the cortex by nature lead to more compact and efficient representation. For example, to achieve 2mm resolution of the cortex, the Human Connectome Project uses a CIFTI file with 91282 vertices and voxels to represent the whole brain. By contrast, the MNI 2mm mask uses 228,483 voxels [Glasser et al. 2013] to cover the brain in volumetric analysis. In addition to reduced file sizes the use of surface-based data formats easilly allows multi-modal data to be quickly aligned and matched within and across subjects greatly improving the speed and ease of analysis [Dickie et al. 2019].</p>
<h2 id="objectives">Objectives</h2>
<p>This practicum will introduce you to some of the steps required for preparing MRI neuroimaging data for group surface-based statistical analysis. These steps have been copied from the <a href="https://github.com/Washington-University/HCPpipelines">Human Connectome Project's Pipelines</a> [Glasser et al. 2013] which have been recreated by <a href="https://github.com/edickie/ciftify">Dickie et al. 2019</a> for non-HCP (aka legacy) data. The scripts for this practicum are described below:</p>
<ul>
<li><code>001_inflate.sh</code> : Use <code>wb_command</code> to create midthickness surface layer and inflated layers.</li>
<li><code>002_register.sh</code>: Use <code>msm</code> and <code>wb_command</code> to register 2 subject meshes to a standard surface template</li>
<li><code>003_projection.sh</code>: Use <code>wb_command</code> to map an fmri volume onto a GIFTI surface mesh</li>
<li><code>004_ciftigen.sh</code>: Use <code>wb_command</code> to map an fmri volume into a CIFTI file</li>
<li><code>005_smoothing.sh</code>: Use <code>wb_command</code> to perform surface-based spatial smoothing on the left and right hemispheres, as well as on the subcortical volume.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please appreciate that the processing tasks you will undertake in this practicum are provided for demonstration purposes only and to shed some light on how these surface processing steps are roughly accomplished. For your research you will want to use one of the robust, established pipelines that not only automate the steps above but utilize the most up-to-date and accurate methods for implementing these steps. The one step that is usually left to the user to do by these pipelines is <strong>spatial smoothing</strong>. However conservative use of spatial smoothing, even when constrained to the surface,  is advised [Coalson et al. 2018].</p>
<p><a href="https://fmriprep.org/en/stable/">FMRIPrep</a> currently performs robust pre-processing on fmri data and can output this out as a surface-based <a href="https://fmriprep.org/en/stable/outputs.html?highlight=cifti#functional-derivatives">CIFTI .dtseries.nii</a> file for surface based analysis. </p>
<p>If you have HCP-style data then you may be able to adapt the <a href="https://github.com/Washington-University/HCPpipelines">HCP Pipelines</a> to work with your data. Alternatively if you have non-HCP data then the <a href="https://github.com/edickie/ciftify">Ciftify pipeline</a> will perform an HCP-style analysis on your data.</p>
<p>And of course <a href="https://surfer.nmr.mgh.harvard.edu/fswiki">Freesurfer</a> has many different tools for surface-based analysis. Many of the steps mentioned above can be accomplished with equivalent freesurfer commands. Most notable of course is that all of the above pipelines depend on freesurfer for the creation of the initial surface mesh models.</p>
<p>In addition to these there are several other tools and methods that can provide a good starting point for developing robust surface-based processing pipelines.</p>
</div>
<h2 id="downloadsinstallation">Downloads/Installation</h2>
<p>This practicum requires the following materials/folder setup for successful completion:</p>
<ul>
<li>A copy of the HCP's <a href="https://www.humanconnectome.org/software/get-connectome-workbench">Connectome workbench</a> for access to <code>wb_view</code>.</li>
<li>You will also need the <a href="https://github.com/edickie/ciftify">Ciftify</a> docker image which you can obtain as follows <code>docker pull tigrlab/fmriprep_ciftify:v1.3.2-2.3.3</code>. This will allow us to run our scripts that call <code>wb_command</code> in a windows environment. It will also give us access to <code>msm</code> if you decide at a later point to fully run the registration step.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will be running the scripts using  the docker container as shown below. For each script a command line will be provided which you will be able to copy and paste into your terminal window. Try to avoid extracting the zip folder into a root directory that has spaces in it to avoid problems with binding the current directory $PWD. If you do have to use a root directory with spaces in it then you can use single quotes in the bind as follows <code>-v '${PWD}':/mnt</code>. Double quotes might also work <code>-v "${PWD}":/mnt.</code></p>
<p>docker run -v ${PWD}:/mnt --rm -it --entrypoint <strong>bash</strong> tigrlab/fmriprep_ciftify:v1.3.2-2.3.3 /mnt/<strong>SCRIPTNAME</strong></p>
</div>
<ul>
<li>The data and scripts for this practicum can be downloaded from <a href="https://drive.google.com/drive/u/1/folders/1xtuQtcPFXFI3wDs2uj6L9p0yd9bagEY5">Classhare</a> folder under the <strong>practicum91</strong> folder in a zip file <strong>practicum91.zip</strong>. Download this zip file to your local computer and extract.</li>
<li>The practicum files can also alternatively be downloaded as a zip file from <a href="https://osf.io/hetgq/">OSF</a> in the folder <strong>09-Surface-Based-Analysis</strong></li>
</ul>
<p>Your folder structure should look like this after extraction.</p>
<pre><code>practicum91
├── 001_inflate.sh
├── 002_register.sh
├── 003_projection.sh
├── 004_ciftigen.sh
├── 005_smoothing.sh
└── DATA
    ├── 100307
    ├── config
    ├── MMP_HCP
    ├── sub-01
    └── sub-02
</code></pre>
<h2 id="provenance">Provenance</h2>
<h3 id="scripts">Scripts</h3>
<p>The scripts for this practicum have been written based on an inspection of the <a href="https://github.com/Washington-University/HCPpipelines">HCP pipelines</a> and the <a href="https://github.com/edickie/ciftify">Ciftify pipelines</a>. Only the essential aspects of the processing steps used in these pipelines have been provided for demonstration purposes and so these scripts are suboptimal for actual research purposes and additionally have not been tested thoroughly.</p>
<h3 id="data">Data</h3>
<p>We will be using a subset of the <a href="https://openneuro.org/datasets/ds000003/versions/00001">Rhyme Judgment</a> data (subjects <code>sub-01</code> and <code>sub-02</code>) acquired by [Xue and Poldrack 2007]. This data has also been used in an FMRIPrep exemplar pipeline for task-based analysis [Esteban et al. 2020]. The data has been processed using fmriprep, freesurfer and ciftify as described further below.</p>
<p>We will also use flat and spherical surfaces from subject <code>100307</code> which is included as part of the Human Connectome Project's Young Adult (YA) <a href="https://db.humanconnectome.org/data/projects/HCP_1200">1200 Subject Release</a>. The HCP has terms of reference for using their data. To use HCP data please sign on to the <a href="https://db.humanconnectome.org">HCP website</a> and register for free.</p>
<p>The folder <code>MMP_HCP</code> contains a subset of the files released for the <a href="https://balsa.wustl.edu/study/show/RVVG">Multi-modal parcellation of Human Cerebral Cortex</a>. This atlas is a comprehensive delineation of about 180 cerebral cortex areas per hemisphere obtained using the HCP's advanced analysis approach [Glasser et al. 2013, Glasser et al. 2016].</p>
<p>Miscellaneous HCP configuration files (atlas and registration templates, MSM Sulc registration config file etc.) are provided in <code>config</code>. These have been copied from the <a href="https://github.com/Washington-University/HCPpipelines">HCP Pipelines</a></p>
<h3 id="initial-processing">Initial processing</h3>
<p>The data was processed initially through <em>FMRIPrep</em> to create aligned fMRI volumes in anatomical space. FMRIprep also uses <em>Freesurfer</em> to generate the initial surface meshes for each subject. The fmriprep processed data was then used as the input to <em>Ciftify</em> to create the final dataset that you have available to you. Several of the Ciftify outputs that are not required for this practicum have been deleted to keep the download manageable.</p>
<h2 id="task-1-create-midthickness-inflated-and-very-inflated-surfaces">Task 1: Create midthickness, inflated and very-inflated surfaces</h2>
<ul>
<li>Open a terminal and navigate to the <code>practicum91</code> folder.</li>
<li>Run the <code>001_inflate.sh</code> script through the docker image as follows:</li>
</ul>
<div class="highlight"><pre><span></span><code>docker run -v ${PWD}:/mnt --rm -it --entrypoint bash tigrlab/fmriprep_ciftify:v1.3.2-2.3.3 /mnt/001_inflate.sh
</code></pre></div>

<ul>
<li>
<p>The script creates the <strong>midthickness</strong> layer <code>amended.sub-01.L.midthickness.32k_fs_LR.surf.gii</code> in the directory <code>practicum91/output/sub-01</code>. This layer lies between the <strong>pial</strong> and the <strong>white</strong> layer and is created using  <code>wb_command -surface-average</code>. This layer is useful for projecting functional data from the volume onto the cortex.</p>
</li>
<li>
<p>The script also creates an <strong>inflated</strong> and a  <strong>very_inflated</strong> layer in the same directory using <code>wb_command -surface-generate-inflated</code>. These layers allow functional areas to be better visualized in the cortex.</p>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The script generates the inflated surfaces from the midthickness layer. This is not strictly how it's done in Freesurfer which instead uses the white surface to create the inflated surfaces.</p>
</div>
<ul>
<li>
<p>If you want to peform this on subject 02 as well then just change the subject variable on line 27 in <code>001_inflate.sh</code> using a simple text editor, as follows <code>SUB=sub-02</code> and rerun the docker command.</p>
</li>
<li>
<p>Open <strong>wb_view</strong> and navigate to <code>./DATA/sub-01/MNINonLinear/</code> and load in <code>T1w.nii.gz</code>. Now navigate up one folder to <code>fsaverage_LR32k</code> and load in the two surfaces <code>sub-01.L.pial.32k_fs_LR.surf.gii</code> and <code>sub-01.L.white.32k_fs_LR.surf.gii</code></p>
</li>
<li>Now load in the midthickness layer you created <code>amended.sub-01.L.midthickness.32k_fs_LR.surf.gii</code> from <code>./output/sub-01</code></li>
<li>Click on the <strong>volume view</strong> and select the <strong>Vol/Surf Tab</strong>. Assign each drop down in the <strong>File</strong> column to one of the three different overlays and assign each a different color.</li>
<li>Notice that your midthickness layer is indeed between the pial and the white layer. You may have to zoom in to see this more clearly.</li>
</ul>
<p><img alt="midthickness" src="../../img/001_inflate_amended.png" /></p>
<ul>
<li>Now we will see how the inflated and very_inflated layers better help us visualize cortical areas. We will also look at the flat layer and a spherical layer that are provided by the HCP's pipelines.</li>
<li>In <strong>wb_view</strong> now load in the inflated <code>amended.sub-01.L.inflated.32k_fs_LR.surf.gii</code> and very_inflated layers <code>amended.sub-01.L.very_inflated.32k_fs_LR.surf.gii</code> from from <code>./output/sub-01</code>.</li>
<li>Navigate to <code>./DATA/MMP_HCP</code> and load in all 4 files that you see there. This is the Human Connectome's <a href="https://balsa.wustl.edu/study/show/RVVG">Multi-modal Parcellation of Human Cerebral Cortex</a> [Glasser et al. 2016]. You might need to change <strong>Files of Type:</strong> to  <code>Any File (*)</code> to be able to see them all.</li>
<li>These files are <code>Q1-Q6_RelatedValidation210.CorticalAreas_dil_Final_Final_Areas_Group_Colors.32k_fs_LR.dlabel.nii</code>, <code>Q1-Q6_RelatedValidation210.L.CorticalAreas_dil_Final_Final_Areas_Group.32k_fs_LR.border</code>, <code>Q1-Q6_RelatedValidation210.R.CorticalAreas_dil_Final_Final_Areas_Group.32k_fs_LR.border</code> and <code>MMP_areas_tangential_32k_bothHems_inflated.wb_annot</code></li>
<li>Finally navigate to <code>./Data/100307</code>  and load in <code>100307.L.flat.32k_fs_LR.surf.gii</code> and <code>100307.L.sphere.32k_fs_LR.surf.gii</code></li>
<li>Click on <strong>Surface View</strong></li>
<li>Activate  the <code>Q1-Q6_RelatedValidation210.CorticalAreas_dil_Final_Final_Areas_Group_Colors.32k_fs_LR.dlabel.nii</code> layer by clicking it's checkbox <strong>On</strong> </li>
<li>In the <strong>Brain Structures and Surface</strong> panel, change the surfaces in turn using the drop down box to see how the Multi Modal Parcellations are rendered on the surface.</li>
<li>Notice how the inflated layers allow you to see cortical areas normally buried in the sulci. Also notice how the flat layer allows you to see both the medial and lateral surfaces at the same time.</li>
</ul>
<p><img alt="midthickness" src="../../img/002_inflated_surfaces.png" /></p>
<h2 id="task-2-use-multimodal-surface-matching-msm-to-register-a-native-mesh-to-the-164k-fs_lr-template">Task 2: Use MultiModal Surface Matching (MSM) to register a native mesh to the 164k fs_LR template</h2>
<ul>
<li>
<p>MultiModal Surface Matching (MSM) [Robinson et al. 2014] is a spherical surface-based registration method that <a href="https://emmarobinson01.com/2020/04/05/advanced-features-of-msm-a-guide/">enhances the traditional approach</a> to surface-based registration by allowing the use of other generalizable brain features (e.g. function, connectivity etc) in addition to  cortical folding to improve brain alignment. In this task however we will not be taking advantage of this enhancement and will be using MSM as any other traditional surface-based registration technique that uses only geometric features to achieve registration..</p>
</li>
<li>
<p>The version of MSM that is contained within the docker container is not the latest version and so takes a considerable amount of time to perform the registration for this practicum. I have thus gone ahead and created the registered spheres ahead of time which are stored in <code>./DATA/sub-??/MSMSulc</code>.</p>
</li>
<li>
<p>If you would like to repeat this part of the exercise yourself then on <code>line 64</code> change the variable <code>BYPASS="Y"</code> to <code>BYPASS="N"</code> and run the docker container. On a 16 GB memory laptop with 8-cores this took about 50 minutes.</p>
</li>
<li>
<p>Run the <code>002_register.sh</code> script through the docker image as follows:</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>docker run -v ${PWD}:/mnt --rm -it --entrypoint bash tigrlab/fmriprep_ciftify:v1.3.2-2.3.3 /mnt/002_register.sh
</code></pre></div>

<ul>
<li>
<p>In this task we are registering just the left hemisphere of a subject to the HCP's high resolution standard space 164k fs_LR.</p>
</li>
<li>
<p>This script performs the following steps:</p>
<ul>
<li>The sulcal overlay is a CIFTI file and this has to be separated into two surface GIFTIs so that we have a measure of sulcal values for the left hemisphere and the right hemisphere</li>
<li>The MSM algorithm then aligns the spherical surface for the subject (<strong>sub-01.L.sphere.rot.native.surf.gii</strong>) with the standard Left Hemisphere 164K_fsLR spherical template (<strong>fsaverage.L_LR.spherical_std.164k_fs_LR.surf.gii</strong>) by matching the sulcal overlay for the left hemisphere that was obtained above with the sulcal overlay template (<strong>L.refsulc.164k_fs_LR.shape.gii</strong>). A "warp field" (<strong>L.sphere.reg.surf.gii</strong>) that describes this alignment is calculated and can then be used to resample surfaces and overlays from the native space to the standard space. </li>
<li>Using <code>wb_command -surface-resample</code> we resample the midthickness surface from native space to the new standard space. This new midthickness surface is called ../DATA/sub-01/amended.sub-01.L.midthickness.164k_fs_LR.surf.gii</li>
<li>Using <code>wb_command -metric-resample</code> we resample the left cortical thickness overlay onto the new left midthickness surface in 164k_fs_LR space.</li>
</ul>
</li>
<li>
<p>Change the script so that the other subject is now processed. Change <code>line 30</code> to point to the new subject (<code>SUB=sub-02</code>) and rerun the docker command.</p>
</li>
<li>
<p>In wb_view, select <strong>File</strong> &gt; <strong>Close All Files</strong> and then open the two resampled surfaces for both subjects i.e. <code>./output/sub-01/sub-01.L.midthickness.164k_fs_LR.surf.gii</code> and <code>./output/sub-02/sub-02.L.midthickness.164k_fs_LR.surf.gii</code> - notice that because both surfaces are registered to the 164K template they have exactly the same number of vertices and that their vertices are in correspondence. Select <strong>Montage</strong> view and deselct the <strong>Medial</strong> checkbox. Ensure that in the <em>Montage Selection</em> both checkboxes are selected and that both surfaces are represented.  Click on either subjects surface mesh to select a vertex and notice that a corresponding vertex is identified on the surface of the other subject. These subject meshes are in vertex correspondence as they have been registered to the same template.</p>
</li>
</ul>
<p><img alt="midthickness" src="../../img/003_register_compare_landmarks.png" /></p>
<ul>
<li>One dramatic way to see how features generalize across subjects is to view the sulc overlay on the sphere. Again <strong>Close all Files</strong> in your current instance of <strong>wb_view</strong>. Now open another separate instance of <strong>wb_view</strong> so that you have two copies of the program running at the same time. In both instances open the standard sphere in <code>./DATA/config/fsaverage.L_LR.spherical_std.164k_fs_LR.surf.gii</code>. In one instance open the resampled sulc overlay that was created by the script at  <code>./output/sub-01/amended.sub-01.L.sulc.164k_fs_LR.shape.gii</code> for subject 01 and in the other instance open the resampled sulc overlay <code>./output/sub-02/amended.sub-02.L.sulc.164k_fs_LR.shape.gii</code> for subject 02. Activate both overlays  and click on <strong>Reset</strong> if your exploration brings your spheres out of sync to bring them back to the default start. The image below uses the <strong>Surface</strong> view to compare hemispheres however you might want to experiment with the <strong>Montage</strong> view. Notice the similarity in the sulcal maps between both subjects as you explore both spheres.</li>
</ul>
<div class="admonition information">
<p class="admonition-title">Information</p>
<p>The sulcal overlay calculates the signed distance that any vertex needs to travel to reach its position in the fully inflated surface. Sulcal vertices will thus have positive numbers and gyral vertices will have negative numbers. This sulcal map is remarkable similar across subjects and is thus a good measure for driving surface-based registration.</p>
</div>
<p><img alt="midthickness" src="../../img/003_register_compare_spheres.png" /></p>
<ul>
<li>Close one of the instances of wb_view when you are ready to move on to the next task.</li>
</ul>
<h2 id="task-3-project-volumetric-data-onto-a-gifti-surface">Task 3: Project volumetric data onto a GIFTI Surface</h2>
<ul>
<li>Run the <code>003_projection.sh</code> script through the docker image as follows:</li>
</ul>
<div class="highlight"><pre><span></span><code>docker run -v ${PWD}:/mnt --rm -it --entrypoint bash tigrlab/fmriprep_ciftify:v1.3.2-2.3.3 /mnt/003_projection.sh
</code></pre></div>

<ul>
<li>
<p>This script uses <code>wb_command -volume-to-surface-mapping</code> to project the volumetric NIFTI-1 functional MRI data at  <code>./DATA/MNINonLinear/Results/task-rhymejudgment/task-rhymejudgment.nii.gz</code> onto the midthickness layer you created in task 1.</p>
</li>
<li>
<p>in wb_view, select <strong>File</strong> &gt; <strong>Close All Files</strong> and then  open the midthickness layer you created in task 1  <code>amended.sub-01.L.midthickness.32k_fs_LR.surf.gii</code> from <code>./output/sub-01</code> and then open the projected surface overlay  <code>sub-01.L.midthickness.32k_fs_LR.func.gii</code> which is in the same directory.</p>
</li>
<li>
<p>Change the file from <code>metricdynconn - sub-01....</code> to  the <code>sub-01.L.midthickness.32k_fs_LR.func.gii</code> layer in the overlay toolbox. Notice that the functional MRI has been successfully projected on the surface. You can cycle through the different volumes by clicking the time index next to the <em>Yoke</em> column in the Overlay Toolbox. Unfortunately we are little limited in what we can do with this GIFTI functional overlay in wb_view. </p>
</li>
</ul>
<p><img alt="midthickness" src="../../img/005_projection.png" /></p>
<ul>
<li>
<p>For example we cannot access the functional data values at individual timepoints (instead we see a long list of all the time values) and also each time point is labelled with 'ribbon constrained' rather than the unique time value in seconds.
<img alt="midthickness" src="../../img/005_projection_list.png" /></p>
</li>
<li>
<p>We do have access to the connectivity layer <code>metricdynconn - sub-01....</code> which is created on the fly but we won't be able to see how the left cortex is connected to the right cortex or to sub-cortical structures at the same time. In the next task we will address the shortcomings of using the GIFTI overlay by creating a CIFTI file which will combine data from both surfaces and subcortical structures into one file.</p>
</li>
</ul>
<p><img alt="midthickness" src="../../img/006_connectivity.png" /></p>
<h2 id="task-4-convert-volumetric-functional-data-into-a-cifti-file">Task 4: Convert volumetric functional data into a CIFTI file</h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The script for this task takes a little longer than the others to complete. It relies on the successful completion of Task 3 for the projection of the functional data onto the left hemisphere. Ensure that that Task 3 has been completed for the subject under study before running this task.</p>
</div>
<ul>
<li>Run the <code>004_ciftigen.sh</code> script through the docker image as follows:</li>
</ul>
<div class="highlight"><pre><span></span><code>docker run -v ${PWD}:/mnt --rm -it --entrypoint bash tigrlab/fmriprep_ciftify:v1.3.2-2.3.3 /mnt/004_ciftigen.sh
</code></pre></div>

<ul>
<li>
<p>This script continues the process of projecting the volume data onto the Right midthickness surface and then samples the sub-cortical data using a sub-cortical mask that covers the key grey-matter areas of the brain. </p>
</li>
<li>
<p>The script then uses <code>wb_command -cifti-create-dense-timeseries</code> to combine the data on the 2 surfaces and on the sub-cortical layer into a CIFTI file.</p>
</li>
<li>
<p>From <code>./output/sub-01</code> open the the left <code>amended.sub-01.L.midthickness.32k_fs_LR.surf.gii</code>and right <code>amended.sub-01.R.midthickness.32k_fs_LR.surf.gii</code> midthickness surfaces and the newly created CIFTI functional MRI overlay,  <code>created.den-91k.sub-01_rest.dtseries.nii</code>. The CIFTI functional overlay provides advantages for viewing and manipulating neuroimaging data.</p>
</li>
<li>
<p>Click on <strong>All</strong> View and change the file from <code>dynconn - created....</code> to  the <code>created.den-91k.sub-01_rest.dtseries.nii</code> layer in the overlay toolbox</p>
</li>
<li>
<p>Notice that we can see the functional data for both hemispheres (surface-based vertices) as well as for the subcortical structures (volumetric voxels) at the same time.</p>
</li>
</ul>
<p><img alt="midthickness" src="../../img/007_ciftifmri.png" /></p>
<ul>
<li>We can also visualize the connectivity between all voxels and vertices at the same time by changing to the <code>dynconn - created....</code>  layer. </li>
</ul>
<p><img alt="midthickness" src="../../img/007_ciftifmri_conn.png" /></p>
<h2 id="task-5-spatial-smoothing">Task 5: Spatial Smoothing</h2>
<ul>
<li>Run the <code>005_smoothing.sh</code> script through the docker image as follows:</li>
</ul>
<div class="highlight"><pre><span></span><code>docker run -v ${PWD}:/mnt --rm -it --entrypoint bash tigrlab/fmriprep_ciftify:v1.3.2-2.3.3 /mnt/005_smoothing.sh
</code></pre></div>

<ul>
<li>
<p>This script simply uses <code>wb_command -cifti-smoothing</code> to spatially smooth our CIFTI fmri file using a gaussian kernel.</p>
</li>
<li>
<p>From <code>./output/sub-01</code> open Surfaces <code>amended.sub-01.L.midthickness.32k_fs_LR.surf.gii</code> and <code>amended.sub-01.R.midthickness.32k_fs_LR.surf.gii</code></p>
</li>
<li>Now also open <code>created.den-91k.sub-01_rest.dtseries.nii</code> and <code>created.den-91k.sub-01_rest.smoothed.dtseries.nii</code></li>
<li>In the <strong>All</strong> or <strong>Surface</strong> view activate the smoothed and non-smoothed layers. Click the top layer off and on to see the blurring effect that spatial smoothing has on the data on the cortical surface. Spatial smoothing helps to reduce the deleterious impact of noise by smoothening peaks in the signal and boosting troughs. However this also has the effect of decreasing the spatial resolution of the data. Conservative use of spatial smoothing is advised [Coalson et al. 2018]. The HCP uses a gaussian kernel of 2mm for smoothing its functional data. If region of interest approaches are used to analyze data then smoothing can be avoided altogether.</li>
</ul>
<p><img alt="midthickness" src="../../img/008_vertsmooth.png" /></p>
<ul>
<li>In the <strong>Volume</strong> view observe the same effect for the sub-cortical voxels.
<img alt="midthickness" src="../../img/008_voxsmooth.png" /></li>
</ul>
<h2 id="extra-time">Extra Time?</h2>
<p>If you have got through this quickly then here are some additional things to try:</p>
<ul>
<li>See if you can adapt the code to work for all the right hemisphere meshes and overlays.</li>
<li>Generate all the surfaces and overlays for subject 02.</li>
<li>Get the MSM algorithm to go through its paces in Task 2 by changing the variable <code>BYPASS="Y"</code> to <code>BYPASS="N"</code></li>
<li>Create your own script and try out different <a href="https://www.humanconnectome.org/software/workbench-command">wb_commands</a></li>
</ul>
<h2 id="final-words">Final words</h2>
<p>This concludes this introduction to using surface-based methods for processing data. A critical step that underpins all of the processing steps above is the creation of the initial surface meshes (<strong>white</strong>, <strong>pial</strong> etc) and overlays (<strong>sulc</strong>, <strong>thickness</strong> etc) by dedicated software like <strong>Freesurfer</strong>. Once these layers have been created then the range of processing steps described above can be accomplished using tools like <code>wb_command</code>, freesurfer modules, custom matlab or python scripts etc.</p>
<p>To gain more experience using <strong>wb_command</strong> then material from the 2019 <a href="https://wustl.app.box.com/v/hcp-2019-practical-08">wb_command course</a> might be useful. Online help on individual workbench commands is available <a href="https://www.humanconnectome.org/software/workbench-command">here</a>. More complex common procedures that require a sequence of different wb_command calls to implement can be called through the <a href="https://github.com/Washington-University/wb_shortcuts">wb_shortcuts</a> script.</p>
<p>Missing from this practicum is any demonstration of how to perform group analysis using surface-based formats. An additional practicum is in development which  will attempt to cover basic group analysis on the surface using tools like <strong>film_gls</strong> and <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/PALM"><strong>PALM</strong></a> which are both part of the <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki">FSL</a> ecosystem and which have been used for the HCP's <a href="https://github.com/Washington-University/HCPpipelines/tree/master/TaskfMRIAnalysis">surface-based task analysis</a>. Development is occurring in this area quite rapidlyuser-friendly tools that facilitate statistical analysis on the surface should be available soon. </p>
<p>Please provide any corrections and suggestions by <a href="mailto:chidiugonna@arizona.edu">email</a> or as issues on <a href="https://github.com/chidiugonna/BrainSurfing">GitHub</a></p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thanks to Dianne Patterson for sharing her comprehehsive notes on <strong>wb_command</strong> which were very helpful and to Tim Coalson for directing me to the HCP's 2019 <a href="https://wustl.app.box.com/v/hcp-2019-practical-08">wb_command course</a>  which provided inspiration.</p>
<h2 id="references">References</h2>
<p>Coalson, T. S., Van Essen, D. C., &amp; Glasser, M. F. (2018). <a href="https://www.pnas.org/content/115/27/E6356.short">The impact of traditional neuroimaging methods on the spatial localization of cortical areas.</a> Proceedings of the National Academy of Sciences, 115(27), E6356-E6365.</p>
<p>Dickie, E. W., Anticevic, A., Smith, D. E., Coalson, T. S., Manogaran, M., Calarco, N., ... &amp; Voineskos, A. N. (2019). <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811919303714">ciftify: A framework for surface-based analysis of legacy MR acquisitions.</a> Neuroimage, 197, 818-826.</p>
<p>Esteban, O., Ciric, R., Finc, K., Blair, R. W., Markiewicz, C. J., Moodie, C. A., ... &amp; Ye, Z. (2020). <a href="https://www.nature.com/articles/s41596-020-0327-3">Analysis of task-based functional MRI data preprocessed with fMRIPrep.</a> Nature Protocols, 1-17.</p>
<p>Glasser, M. F., Sotiropoulos, S. N., Wilson, J. A., Coalson, T. S., Fischl, B., Andersson, J. L., ... &amp; Van Essen, D. C. (2013). <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811913005053?via%3Dihub">The minimal preprocessing pipelines for the Human Connectome Project.</a> Neuroimage, 80, 105-124.</p>
<p>Glasser, M. F., Coalson, T. S., Robinson, E. C., Hacker, C. D., Harwell, J., Yacoub, E., ... &amp; Smith, S. M. (2016). <a href="https://www.nature.com/articles/nature18933">A multi-modal parcellation of human cerebral cortex.</a> Nature, 536(7615), 171-178.</p>
<p>Robinson, E. C., Jbabdi, S., Glasser, M. F., Andersson, J., Burgess, G. C., Harms, M. P., ... &amp; Jenkinson, M. (2014). <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811914004546">MSM: a new flexible framework for Multimodal Surface Matching</a>. Neuroimage, 100, 414-426.</p>
<p>Xue, G., &amp; Poldrack, R. A. (2007). <a href="https://www.mitpressjournals.org/doi/abs/10.1162/jocn.2007.19.10.1643">The neural substrates of visual perceptual learning of words: implications for the visual word form area hypothesis.</a> Journal of cognitive neuroscience, 19(10), 1643-1655.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="../../surfdata/prac81/" class="btn btn-neutral" title="practicum 8.1"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../../surfdata/prac81/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
